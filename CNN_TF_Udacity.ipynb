{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-TF-Udacity.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/marcionicolau/ml-colab/blob/master/CNN_TF_Udacity.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ddnyD8FwURXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "cf6266a8-733d-4f61-995e-8042acc045a5"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-468ca9d84ac9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "peCMX8OwUn0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# parameters\n",
        "lr = 0.00001\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "test_valid_size = 256\n",
        "\n",
        "# network Parameters\n",
        "n_classes = 10\n",
        "dropout = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JdtORvf5WQeu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# store weights & biases\n",
        "weights = {\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVPPZ01vWUaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "  x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "  x = tf.nn.bias_add(x, b)\n",
        "  return tf.nn.relu(x)\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "  return tf.nn.max_pool(\n",
        "  x,\n",
        "  ksize=[1,k,k,1],\n",
        "  strides=[1,k,k,1],\n",
        "  padding='SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w09lIbGHW7-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_net(x, weights, biases, dropout):\n",
        "  conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "  conv1 = maxpool2d(conv1, k=2)\n",
        "  \n",
        "  conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "  conv2 = maxpool2d(conv2, k=2)\n",
        "  \n",
        "  fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "  fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "  fc1 = tf.nn.relu(fc1)\n",
        "  fc1 = tf.nn.dropout(fc1, dropout)\n",
        "  \n",
        "  out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCrQIFtbX5C2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "y = tf.placeholder(tf.float32, [None, n_classes])\n",
        "keep_prob = tf.placeholder(tf.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FCUcxlaqX-4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model\n",
        "logits = conv_net(x, weights, biases, keep_prob)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(\\\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\\\n",
        "    .minimize(cost)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YPwhRrejYBpW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf. global_variables_initializer()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKhYLkfPYVhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12eb5599-a147-401e-85b8-4610d4f94e67"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(mnist.train.num_examples//batch_size):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            sess.run(optimizer, feed_dict={\n",
        "                x: batch_x,\n",
        "                y: batch_y,\n",
        "                keep_prob: dropout})\n",
        "\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss = sess.run(cost, feed_dict={\n",
        "                x: batch_x,\n",
        "                y: batch_y,\n",
        "                keep_prob: 1.})\n",
        "            valid_acc = sess.run(accuracy, feed_dict={\n",
        "                x: mnist.validation.images[:test_valid_size],\n",
        "                y: mnist.validation.labels[:test_valid_size],\n",
        "                keep_prob: 1.})\n",
        "\n",
        "            print('\\rEpoch {:>2}, Batch {:>3} -'\n",
        "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
        "                epoch + 1,\n",
        "                batch + 1,\n",
        "                loss,\n",
        "                valid_acc), end=\"\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    # Calculate Test Accuracy\n",
        "    test_acc = sess.run(accuracy, feed_dict={\n",
        "        x: mnist.test.images[:test_valid_size],\n",
        "        y: mnist.test.labels[:test_valid_size],\n",
        "        keep_prob: 1.})\n",
        "    print('Testing Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  2, Batch 411 -Loss:   618.9946 Validation Accuracy: 0.707031"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bPk3JHZeYfD0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}